Perfeito, obrigado pelos esclarecimentos! Vou iniciar uma pesquisa profunda para identificar, comparar e recomendar as melhores opções atuais para cada camada da stack: frontend GUI para desktop, motor de escaneamento de duplicatas (imagens e vídeos), manipulação de arquivos/sistema com suporte a multithreading e Lixeira do Windows, e descompactação otimizada para formatos comuns.

Vou priorizar soluções prontas para produção, considerar tanto opções open source quanto comerciais, cobrir suporte a CPU e GPU onde aplicável, e focar em formatos populares de compressão.

Já volto com uma análise completa, formatada em português e estruturada conforme seu modelo solicitado!

# Melhores Opções por Camada para Detecção de Duplicatas em Python

## 1. GUI (Frontend) para Desktop Windows

**Top 5 Candidatos (Frameworks GUI):**

- **PySide6 (Qt for Python)** – [Documentação Oficial](https://doc.qt.io/qtforpython/)  
- **PyQt6** – [Riverbank Computing (Site Oficial)](https://riverbankcomputing.com/software/pyqt/intro)  
- **Kivy** – [Site Oficial kivy.org](https://kivy.org)  
- **wxPython** – [Site Oficial wxpython.org](https://www.wxpython.org)  
- **Dear PyGui** – [Repositório GitHub](https://github.com/hoffstadt/DearPyGui)  

**Resumo Comparativo:**  
**PySide6 (Qt for Python)** e **PyQt6** fornecem bindings para o framework Qt 6, permitindo criar interfaces modernas e profissionais em Python. Ambas oferecem um conjunto vasto de **componentes nativos (botões, tabelas, gráficos, multimídia, etc.)**, excelente suporte multiplataforma e alto desempenho por serem implementadas em C++ ([
        Which Python GUI library should you use in 2025?

    ](https://www.pythonguis.com/faq/which-python-gui-library/#:~:text=Qt%20,usable%20and%20isolated%20components)) ([GitHub - hoffstadt/DearPyGui: Dear PyGui: A fast and powerful Graphical User Interface Toolkit for Python with minimal dependencies](https://github.com/hoffstadt/DearPyGui#:~:text=Dear%20PyGui%20is%20built%20on,supported%20on%20the%20following%20platforms)). A principal diferença está na licença: *PyQt6* é mantido pela Riverbank e requer licença GPL (ou comercial) para uso fechado, enquanto *PySide6* é oficialmente mantido pela Qt Company sob LGPL (uso livre inclusive comercial) ([TOP 10 Best Python Libraries for GUI in 2025 - Developer Should Know](https://stepmediasoftware.com/blog/best-gui-library-for-python/#:~:text=Image%3A%20Top%2010%20best%20GUI,to%20PyQt%20for%20professional%20projects)) ([Riverbank Computing | Introduction](https://riverbankcomputing.com/software/pyqt/intro#:~:text=License)). Em termos de funcionalidades e API, elas são praticamente equivalentes, ambas suportando interfaces complexas e aplicações de grande porte. O **pró** de usar Qt (PySide6/PyQt6) é a **qualidade profissional e ecossistema rico** (Designer visual, internacionalização, impressão, etc.) ([
        Which Python GUI library should you use in 2025?

    ](https://www.pythonguis.com/faq/which-python-gui-library/#:~:text=Qt%20,usable%20and%20isolated%20components)) ([Riverbank Computing | Introduction](https://riverbankcomputing.com/software/pyqt/intro#:~:text=Qt%20is%20more%20than%20a,rich%20collection%20of%20GUI%20widgets)). Como *contra*, há **curva de aprendizado moderada** e o tamanho das bibliotecas Qt (deploy maior). Além disso, PyQt6 pode implicar custos de licença em projetos proprietários ([TOP 10 Best Python Libraries for GUI in 2025 - Developer Should Know](https://stepmediasoftware.com/blog/best-gui-library-for-python/#:~:text=PyQt%20is%20very%20worthwhile%20for,license%20required%20for%20commercial%20projects)) ([Riverbank Computing | Introduction](https://riverbankcomputing.com/software/pyqt/intro#:~:text=License)). Apesar disso, é considerado o **padrão ouro** para GUIs em Python – “ideal para software de qualidade comercial” ([
        Which Python GUI library should you use in 2025?

    ](https://www.pythonguis.com/faq/which-python-gui-library/#:~:text=tldr%20If%20you%27re%20looking%20to,tutorial%20%20and%20%2019)) – com ampla comunidade e recursos disponíveis.

**Kivy** é um framework GUI *open source* escrito em Python/Cython focado em **experiências multimídia e interfaces multitouch**. Ele permite escrever uma única base de código para Windows, Linux, macOS e dispositivos móveis (Android/iOS) ([Top 12 Python GUI Frameworks for Developers | Built In](https://builtin.com/software-engineering-perspectives/python-gui#:~:text=With%20Kivy%2C%20interface%20designers%20can,Raspberry%20Pi%20and%20macOS%20devices)) ([Top 12 Python GUI Frameworks for Developers | Built In](https://builtin.com/software-engineering-perspectives/python-gui#:~:text=powerful%20graphics%20and%20design%20techniques,Raspberry%20Pi%20and%20macOS%20devices)). Seus pontos fortes incluem **aceleração GPU via OpenGL ES 2.0**, permitindo animações e gráficos fluidos, e widgets altamente customizáveis. Assim, Kivy tem ótimo desempenho gráfico e é indicado para aplicativos com interfaces inovadoras, touch apps ou mesmo pequenos jogos ([TOP 10 Best Python Libraries for GUI in 2025 - Developer Should Know](https://stepmediasoftware.com/blog/best-gui-library-for-python/#:~:text=Kivy%20is%20an%20open,touch%20functionality)). Por outro lado, um **contra** é que os componentes visuais do Kivy não seguem o estilo nativo de cada OS (usa seu próprio visual), o que pode impactar a familiaridade da UI no Windows. Além disso, a comunidade é menor que a de Qt e a quantidade de widgets pré-prontos é mais limitada, exigindo eventualmente mais esforço para construir certos componentes padrão ([TOP 10 Best Python Libraries for GUI in 2025 - Developer Should Know](https://stepmediasoftware.com/blog/best-gui-library-for-python/#:~:text=Kivy%20is%20strong%20when%20it,and%20support%20for%20multiple%20platforms)). Kivy pode ter uma curva de aprendizagem um pouco diferente (usa linguagem KV para layout) e, apesar de muito eficiente em cenários específicos, para aplicativos desktop tradicionais (formulários, tabelas) o Qt costuma oferecer mais facilidade.

**wxPython** é um binding para a biblioteca wxWidgets (C++). Destaca-se por **renderizar controles nativos do sistema operacional**, fornecendo uma aparência autêntica do Windows na GUI ([TOP 10 Best Python Libraries for GUI in 2025 - Developer Should Know](https://stepmediasoftware.com/blog/best-gui-library-for-python/#:~:text=wxPython%20is%20an%20open,widgets%20and%20lots%20of%20customization)). Suporta também macOS e Linux com o mesmo código. Como pró, possui **boa performance e muitos widgets** disponíveis – é maduro, existente há décadas. Também não impõe restrições de licença (wxWidgets é LGPL com exceções liberal). O **ecossistema** é um pouco menor comparado ao Qt, mas ainda há uma gama de componentes (menus, diálogos, etc.) e documentação razoável. Entre os **contras**: wxPython pode ser mais **trabalhoso de aprender** devido a documentação e exemplos dispersos, e historicamente houve atrasos em acompanhar as versões do wxWidgets. Ainda assim, está estável (v4.x “Phoenix”) e adequado para apps que queiram **integração visual nativa** e desempenho decente ([TOP 10 Best Python Libraries for GUI in 2025 - Developer Should Know](https://stepmediasoftware.com/blog/best-gui-library-for-python/#:~:text=3)) ([TOP 10 Best Python Libraries for GUI in 2025 - Developer Should Know](https://stepmediasoftware.com/blog/best-gui-library-for-python/#:~:text=While%20wxPython%20provides%20native%20interfaces%2C,deal%20of%20customization%20that%20typical)). A comunidade é menor que Qt’s, mas dedicada. Em suma, wxPython é uma opção sólida se desejamos aparência nativa e não precisamos do extenso conjunto de módulos extras que o Qt oferece.

**Dear PyGui** é um framework Python relativamente novo, focado em **alta performance via GPU e interfaces em modo imediato** (inspirado no Dear ImGui) ([TOP 10 Best Python Libraries for GUI in 2025 - Developer Should Know](https://stepmediasoftware.com/blog/best-gui-library-for-python/#:~:text=Dear%20PyGui%20is%20a%20newer,a%20lot%20of%20interactive%20features)) ([GitHub - hoffstadt/DearPyGui: Dear PyGui: A fast and powerful Graphical User Interface Toolkit for Python with minimal dependencies](https://github.com/hoffstadt/DearPyGui#:~:text=Dear%20PyGui%20is%20built%20on,supported%20on%20the%20following%20platforms)). Seus diferenciais estão na renderização extremamente rápida de gráficos e widgets (utiliza **DirectX/Metal/OpenGL via GPU**) e na simplicidade de criar *tools* interativas, visando especialmente aplicações de visualização de dados, editor gráficos ou utilitários científicos em que performance em tempo real é crucial ([TOP 10 Best Python Libraries for GUI in 2025 - Developer Should Know](https://stepmediasoftware.com/blog/best-gui-library-for-python/#:~:text=Dear%20PyGui%20is%20a%20newer,a%20lot%20of%20interactive%20features)) ([TOP 10 Best Python Libraries for GUI in 2025 - Developer Should Know](https://stepmediasoftware.com/blog/best-gui-library-for-python/#:~:text=The%20good%20things%20about%20Dear,data%20analysis%20tools%2C%20and%20apps)). Prós: possui **desempenho elevadíssimo** para interfaces dinâmicas, suporte a elementos como plots e nós, e API pythonica bem simples (modo imediato) ([GitHub - hoffstadt/DearPyGui: Dear PyGui: A fast and powerful Graphical User Interface Toolkit for Python with minimal dependencies](https://github.com/hoffstadt/DearPyGui#:~:text=Dear%20PyGui%20is%20built%20on,supported%20on%20the%20following%20platforms)). Além disso, é multiplataforma e leve (mínimas dependências). **Contras:** por ser relativamente novo, sua **comunidade e ecosssitema são pequenos** e menos testados ([TOP 10 Best Python Libraries for GUI in 2025 - Developer Should Know](https://stepmediasoftware.com/blog/best-gui-library-for-python/#:~:text=The%20good%20things%20about%20Dear,data%20analysis%20tools%2C%20and%20apps)). Faltam muitos componentes avançados presentes no Qt ou wx (por exemplo, controles nativos complexos, árvores, rico suporte a acessibilidade). Assim, Dear PyGui é ótimo para aplicações gráficas especializadas (ex.: ferramentas de visualização científica, demos gráficas), mas talvez não ideal como GUI “tradicional” completa. Ainda assim, está em rápido desenvolvimento e já é utilizado quando se prioriza interface altamente responsiva.

**Recomendação Final:** Para uma aplicação desktop profissional no Windows, privilegiando **desempenho, UX nativa e riqueza de componentes**, a recomendação é usar **Qt** através de **PySide6** (ou PyQt6) como camada GUI. O Qt se destaca pela maturidade e extenso conjunto de funcionalidades – essencial para um aplicativo de detecção de duplicatas com interface rica (listas de arquivos, prévias de mídia, diálogos avançados etc.). PySide6 em particular evita preocupações de licenciamento e é mantido oficialmente (garantia de atualizações) ([TOP 10 Best Python Libraries for GUI in 2025 - Developer Should Know](https://stepmediasoftware.com/blog/best-gui-library-for-python/#:~:text=PySide%2C%20another%20open,use%2C%20even%20for%20commercial%20projects)). Ele tem suporte a **threading** integrado (necessário se a interface precisar permanecer responsiva durante scans) e se integra bem com Python. Alternativamente, se a interface for relativamente simples ou focada em visualização customizada, **Dear PyGui** seria uma escolha secundária pela performance bruta (aplicando GPU) ([TOP 10 Best Python Libraries for GUI in 2025 - Developer Should Know](https://stepmediasoftware.com/blog/best-gui-library-for-python/#:~:text=Dear%20PyGui%20is%20a%20newer,a%20lot%20of%20interactive%20features)), porém o ecossistema Qt (documentação, comunidade, ferramentas) tende a acelerar o desenvolvimento e oferecer uma UI mais polida ao usuário. Em resumo, **PySide6 (Qt)** equilibra melhor a **experiência do usuário** e a **produtividade do desenvolvedor**, sendo a opção mais completa para o frontend.

**Referências (GUI):** 

- Fitzpatrick, M. *“Which Python GUI library should you use?”* Python GUIs (2025) – Comparativo de frameworks (PySide6/PyQt6 recomendados como opção profissional) ([
        Which Python GUI library should you use in 2025?

    ](https://www.pythonguis.com/faq/which-python-gui-library/#:~:text=tldr%20If%20you%27re%20looking%20to,tutorial%20%20and%20%2019)) ([
        Which Python GUI library should you use in 2025?

    ](https://www.pythonguis.com/faq/which-python-gui-library/#:~:text=Qt%20,usable%20and%20isolated%20components)).  
- StepMedia Software Blog (2025) – *“Top 10 Best GUI libraries for Python”* – descrição de prós/contras de Tkinter, PyQt, Kivy, wxPython, PySide, Dear PyGui, etc ([TOP 10 Best Python Libraries for GUI in 2025 - Developer Should Know](https://stepmediasoftware.com/blog/best-gui-library-for-python/#:~:text=With%20it%2C%20all%20your%20applications,robust%20signal%20and%20slot%20system)) ([TOP 10 Best Python Libraries for GUI in 2025 - Developer Should Know](https://stepmediasoftware.com/blog/best-gui-library-for-python/#:~:text=Dear%20PyGui%20is%20a%20newer,a%20lot%20of%20interactive%20features)).  
- Documentação do Send2Trash (2021) – nota sobre integração com IFileOperation/SHFileOperation no Windows ([Send2Trash · PyPI](https://pypi.org/project/Send2Trash/#:~:text=Send2Trash%20is%20a%20small%20package,org)).  
- GitHub – **hoffstadt/DearPyGui** (2023) – README destacando uso de GPU e paradigma de imediato para alta dinâmica ([GitHub - hoffstadt/DearPyGui: Dear PyGui: A fast and powerful Graphical User Interface Toolkit for Python with minimal dependencies](https://github.com/hoffstadt/DearPyGui#:~:text=Dear%20PyGui%20is%20built%20on,supported%20on%20the%20following%20platforms)).  

## 2. Motor de Escaneamento de Duplicatas Idênticas (Hashing/Comparação)

**Top 4 Candidatos (Bibliotecas de Hash/Comparação):**

- **hashlib (Stdlib Python)** – [Documentação Oficial](https://docs.python.org/3/library/hashlib.html)  
- **BLAKE3 (implementação Python)** – [Repositório oficial no GitHub](https://github.com/BLAKE3-team/BLAKE3)  
- **xxHash** – [Site oficial xxhash.com](https://xxhash.com) (algoritmo e implementação em C; binding Python via pacote `xxhash`)  
- **Hashwise (GPU Hashing)** – [PyPI Hashwise](https://pypi.org/project/hashwise/) (biblioteca Python com suporte a CUDA)  

**Resumo Comparativo:**  
Para detectar arquivos **idênticos** (fotos/vídeos duplicados byte a byte), a abordagem comum é calcular um **hash** de cada arquivo e comparar valores iguais. O Python oferece nativamente o módulo **hashlib**, que inclui algoritmos criptográficos como MD5, SHA-1, SHA-256 etc. A vantagem do hashlib é a **facilidade e confiabilidade** – é implementado em C/OpenSSL, liberando o GIL para processar dados grandes e aproveitando instruções de hardware (por ex, SHA usa extensões AES-NI) ([hashlib — Secure hashes and message digests — Python 3.13.3 ...](https://docs.python.org/3/library/hashlib.html#:~:text=hashlib%20%E2%80%94%20Secure%20hashes%20and,update%20method)). Em múltiplas threads, diferentes arquivos podem ter hash calculado em paralelo sem contenção significativa ([hashlib — Secure hashes and message digests — Python 3.13.3 ...](https://docs.python.org/3/library/hashlib.html#:~:text=hashlib%20%E2%80%94%20Secure%20hashes%20and,update%20method)). Entretanto, alguns hashes do hashlib (ex: SHA-2) podem ser relativamente **lentos** para volumes massivos de dados, e algoritmos legados como MD5/SHA1, embora rápidos, têm conhecidas vulnerabilidades de colisão (irrelevantes para integridade básica, mas vale notar) ([Use Fast Data Algorithms | Joey Lynch's Site](https://jolynch.github.io/posts/use_fast_data_algorithms/#:~:text=,on%20most%20servers%20I%20encounter)). Ainda assim, MD5 é frequentemente utilizado em ferramentas de deduplicação por ser um compromisso entre velocidade e baixa taxa de colisão. Uma melhoria moderna é usar **BLAKE3**, um hash criptográfico de última geração projetado para **ser muito mais rápido** que MD5/SHA, mantendo forte segurança ([GitHub - BLAKE3-team/BLAKE3: the official Rust and C implementations of the BLAKE3 cryptographic hash function](https://github.com/BLAKE3-team/BLAKE3#:~:text=BLAKE3%20is%20a%20cryptographic%20hash,function%20that%20is)). Implementações BLAKE3 (em Rust/C) conseguem throughput impressionante (graças a paralelismo interno e SIMD): *“bem mais rápido que MD5, SHA-1/2...”* ([GitHub - BLAKE3-team/BLAKE3: the official Rust and C implementations of the BLAKE3 cryptographic hash function](https://github.com/BLAKE3-team/BLAKE3#:~:text=BLAKE3%20is%20a%20cryptographic%20hash,function%20that%20is)) – por exemplo, ~10x a velocidade do MD5 em um núcleo, e escalando em múltiplos núcleos quase linearmente ([Use Fast Data Algorithms | Joey Lynch's Site](https://jolynch.github.io/posts/use_fast_data_algorithms/#:~:text=Expect%20,A)). A biblioteca Python `blake3` integra a implementação oficial (em Rust) e pode atingir velocidades de leitura próximas ao limite do disco. Portanto, **BLAKE3** é excelente para escanear grandes coleções rapidamente, oferecendo **hash seguro e extremamente veloz**. Como contra, por ser relativamente novo, é menos ubiquamente suportado que MD5/SHA1 em outras ferramentas, mas isso não afeta o uso interno.

Outra opção voltada puramente à performance é usar **xxHash**, um algoritmo não-criptográfico otimizado para velocidade. Via binding Python (`xxhash`), obtém-se hashing a *“velocidade de RAM”* – até **10x mais rápido que MD5** em dados grandes ([Use Fast Data Algorithms | Joey Lynch's Site](https://jolynch.github.io/posts/use_fast_data_algorithms/#:~:text=Expect%20,A)) e ainda com baixa incidência de colisões práticas (64 ou 128 bits de saída) ([Use Fast Data Algorithms | Joey Lynch's Site](https://jolynch.github.io/posts/use_fast_data_algorithms/#:~:text=Try%20xxHash,you%E2%80%99re%20hashing%20data%20for%20a)). O xxHash é útil quando desejamos máxima rapidez e aceitamos uma possibilidade extremamente remota de colisão não maliciosa. Em cenários de deduplicação, é comum usar um hash muito rápido como xxHash ou CRC inicialmente para agrupar candidatos e, em seguida, verificar byte a byte ou com um hash criptográfico para confirmação. Vale notar que **BLAKE3 quase alcança o desempenho do xxHash** em um thread (um pouco mais lento, ~1.2x o tempo do xxHash) ([Use Fast Data Algorithms | Joey Lynch's Site](https://jolynch.github.io/posts/use_fast_data_algorithms/#:~:text=Expect%20,A)), portanto se BLAKE3 estiver disponível, podemos obter velocidade próxima com garantia criptográfica. Ainda assim, xxHash é simples e pode atingir >20 GB/s em CPUs modernas ([Use Fast Data Algorithms | Joey Lynch's Site](https://jolynch.github.io/posts/use_fast_data_algorithms/#:~:text=Expect%20,A)), o que pode ser útil ao comparar muitos arquivos pequenos.

Para verificar definitivamente duplicatas, além de hashes iguais, pode-se fazer uma **comparação byte-a-byte** direta nos arquivos suspeitos. Isso pode ser realizado manualmente (abrindo ambos e lendo em blocos) ou via funções como `filecmp.cmp` do Python. Essa etapa elimina qualquer chance de colisão, garantindo que arquivos com mesmo hash realmente sejam idênticos. A penalidade é ler novamente os arquivos envolvidos, mas normalmente só será aplicada a poucos candidatos que já tiveram hash coincidente e tamanho igual. Uma boa prática é assegurar que o algoritmo escolhido tenha saída de tamanho suficiente (ex.: 128 bits no xxHash3) para minimizar colisões fortuitas ([Use Fast Data Algorithms | Joey Lynch's Site](https://jolynch.github.io/posts/use_fast_data_algorithms/#:~:text=Try%20xxHash,you%E2%80%99re%20hashing%20data%20for%20a)). Hashes criptográficos como SHA-256 ou BLAKE3 virtualmente não terão colisões para esse uso, dispensando a necessidade de verificação extra byte a byte na maioria dos casos – a não ser por paranoia ou para confirmar duplicatas antes de remover.

Finalmente, considerando **suporte a GPU**, embora hashing não seja trivialmente acelerável em GPU (devido à natureza serial de muitos algoritmos), a biblioteca **Hashwise** explora CUDA para acelerar o cálculo de diversos hashes (MD5, SHA-2, SHA-3, BLAKE2, etc.) ([hashwise · PyPI](https://pypi.org/project/hashwise/#:~:text=This%20library%20provides%20a%20set,to%20speed%20up%20the%20process)) ([hashwise · PyPI](https://pypi.org/project/hashwise/#:~:text=,%60sha3_224%28payload%3Abytes)). Ela pode computar hashes usando kernels na GPU, beneficiando cenários com **muitos arquivos sendo processados em paralelo**. Por exemplo, se houver milhares de arquivos pequenos, a GPU pode hashá-los concorrentemente, o que pode superar a CPU. Contudo, para um arquivo individual grande, a limitação é que algoritmos como SHA-256 não paralelizam internamente facilmente – então a GPU ajuda pouco a não ser que se particione o arquivo (o que BLAKE3 já faz internamente com CPU multi-thread). O Hashwise também oferece funções de *brute-force* hashes usando GPU (não necessário para dedupe, mas indicativo de sua finalidade). Um ponto a considerar é a complexidade de dependências – ele requer CUDA e configuração correta de drivers, o que adiciona peso à aplicação. Alternativamente, pode-se obter aceleração customizada usando bibliotecas como **PyCUDA/cuPY** ou **OpenCL** para implementar hashes, mas isso demandaria muito esforço e não há soluções prontas focadas em hashing genérico além do Hashwise. Dado que CPUs modernas já alcançam dezenas de gigabytes/s com BLAKE3/xxHash, a GPU é opcional e provavelmente só traria benefício marginal em casos específicos.

**Recomendação Final:** Para identificar duplicatas exatas de forma eficiente, recomenda-se uma abordagem híbrida usando **hashes rápidos seguidos de verificação**. Em particular, **BLAKE3** desponta como a melhor escolha geral para o motor de hashing – ele oferece **velocidade equiparável ao hash não-cripto mais rápido** (xxHash) em cenário multi-thread, com a tranquilidade de praticamente zero colisões ([Use Fast Data Algorithms | Joey Lynch's Site](https://jolynch.github.io/posts/use_fast_data_algorithms/#:~:text=Expect%20,A)) ([GitHub - BLAKE3-team/BLAKE3: the official Rust and C implementations of the BLAKE3 cryptographic hash function](https://github.com/BLAKE3-team/BLAKE3#:~:text=,64%20and%20also%20on%20smaller)). Assim, podemos calcular o BLAKE3 de cada arquivo (explorando todos os núcleos da CPU automaticamente) e comparar os hashes para encontrar duplicatas. Para arquivos muito grandes (ex.: vídeos 4K), BLAKE3 ainda brilha pois faz uso ótimo de paralelismo e I/O streaming. Em caso de não ser viável usar BLAKE3, a combinação **xxHash + confirmação** é a segunda melhor: usa-se xxHash para marcar prováveis duplicatas e então um SHA-256 ou comparação bit a bit para confirmar coincidências. A biblioteca padrão **hashlib** já supre MD5/SHA-1/SHA-256 com bom desempenho (e libera GIL para threads paralelas) ([hashlib — Secure hashes and message digests — Python 3.13.3 ...](https://docs.python.org/3/library/hashlib.html#:~:text=hashlib%20%E2%80%94%20Secure%20hashes%20and,update%20method)), então é perfeitamente possível usá-la – por exemplo, MD5 de cada arquivo seguido de uma verificação adicional se desejado. Porém, dado o estado atual, utilizar uma biblioteca otimizada como `blake3` irá **reduzir sensivelmente o tempo de varredura** em coleções grandes. Quanto ao uso de **GPU**, para a maioria dos casos não é essencial; a CPU consegue hash eficiente enquanto o gargalo tende a ser a leitura do disco. A opção **Hashwise** com CUDA poderia ser avaliada se o ambiente tiver GPU disponível e se o *throughput* de hashing CPU for insuficiente – por exemplo, em um sistema que precisa verificar milhões de arquivos o mais rápido possível. No geral, **BLAKE3 (CPU)** é a recomendação por equilibrar simplicidade de adoção, alta performance e robustez criptográfica, tornando o motor de escaneamento de duplicatas extremamente rápido e confiável.

**Referências (Hashing):** 

- Lynch, J. *“Use Fast Data Algorithms”* (2021) – discussão sobre desempenho de hashes (xxHash ~10x mais rápido que MD5; BLAKE3 ligeiramente mais lento que xxHash single-thread) ([Use Fast Data Algorithms | Joey Lynch's Site](https://jolynch.github.io/posts/use_fast_data_algorithms/#:~:text=Expect%20,A)) ([Use Fast Data Algorithms | Joey Lynch's Site](https://jolynch.github.io/posts/use_fast_data_algorithms/#:~:text=completely,wish%20more%20systems%20used%20them)).  
- README oficial do BLAKE3 (2020) – destaca velocidade superior a MD5/SHA e paralelização via árvore de Merkle ([GitHub - BLAKE3-team/BLAKE3: the official Rust and C implementations of the BLAKE3 cryptographic hash function](https://github.com/BLAKE3-team/BLAKE3#:~:text=BLAKE3%20is%20a%20cryptographic%20hash,function%20that%20is)).  
- Documentação Python `hashlib` (v3.13) – nota que implementações liberam GIL e usam otimizações de baixo nível para eficiência em dados grandes ([hashlib — Secure hashes and message digests — Python 3.13.3 ...](https://docs.python.org/3/library/hashlib.html#:~:text=hashlib%20%E2%80%94%20Secure%20hashes%20and,update%20method)).  
- PyPI `hashwise` (2023) – descrição da biblioteca de hashing GPU em Python (usa CUDA para acelerar MD5, SHA, etc.) ([hashwise · PyPI](https://pypi.org/project/hashwise/#:~:text=This%20library%20provides%20a%20set,to%20speed%20up%20the%20process)) ([hashwise · PyPI](https://pypi.org/project/hashwise/#:~:text=Additionally%2C%20we%20can%20specify%20the,optimal%20configuration%20will%20be%20used)).  
- Comentários no blog de Joey Lynch (2021) – recomendação de xxHash para integridade de dados rápida e BLAKE3 como alternativa criptográfica rápida ([Use Fast Data Algorithms | Joey Lynch's Site](https://jolynch.github.io/posts/use_fast_data_algorithms/#:~:text=Try%20xxHash,you%E2%80%99re%20hashing%20data%20for%20a)) ([Use Fast Data Algorithms | Joey Lynch's Site](https://jolynch.github.io/posts/use_fast_data_algorithms/#:~:text=Expect%20,A)).  

## 3. Manipulação de Arquivos & Sistema (I/O, Delete/Restore)

**Top 4 Candidatos (Bibliotecas de Arquivos/SO):**

- **Shutil / os (Biblioteca Padrão)** – [Documentação shutil](https://docs.python.org/3/library/shutil.html)  
- **Send2Trash** – [PyPI Send2Trash](https://pypi.org/project/Send2Trash/)  
- **Winshell** – [PyPI winshell](https://pypi.org/project/winshell/)  
- **PyWin32** (win32api/win32file) – [Docs PyWin32](https://pywin32.readthedocs.io/)  

**Resumo Comparativo:**  
A manipulação intensiva de arquivos em Windows envolve operações de **cópia, movimentação, exclusão (preferencialmente enviando à Lixeira) e restauração**. A biblioteca padrão do Python fornece ferramentas robustas: o módulo **shutil** cobre cópia de arquivos e diretórios, remoção recursiva, movimentação, etc., enquanto **os/os.path** lida com operações de nível mais baixo (remover, renomear, listar diretórios). Por ser código em C dentro do interpretador, shutil já oferece um desempenho aceitável – e a partir do Python 3.8 foram adicionadas otimizações de cópia rápida. Por exemplo, no Windows o `shutil.copyfile` passou a usar um buffer de 1 MiB (em vez de 64 KiB) e *memoryview* para reduzir chamadas em Python, acelerando a transferência ([shutil — High-level file operations — Python 3.13.3 documentation](https://docs.python.org/3/library/shutil.html#:~:text=On%20Linux%20os)). Em Unix, utiliza-se chamadas do kernel (`sendfile`) para ganhos semelhantes. Benchmarks mostram melhorias de ~30-50% nessas otimizações em relação ao método antigo ([GitHub - desbma/pyfastcopy: Speed up Python's shutil.copyfile by using sendfile system call](https://github.com/desbma/pyfastcopy#:~:text=Image%3A%20graph6)). Em testes práticos, shutil pode atingir velocidades próximas ao comando nativo do OS para cópia simples. Entretanto, chamadas nativas como CopyFileEx do Windows podem ser ainda mais eficientes em certos casos (e.g. cópia de arquivos muito grandes), e não são usadas diretamente pelo shutil (que opta por abordagem manual com buffer). Nesse aspecto, a utilização de **pywin32** (módulo win32file) permite chamar a API do Windows – por exemplo, `win32file.CopyFile()` ou `SHFileOperation` – potencialmente aproveitando funcionalidades extras do OS (como cópia assíncrona ou com barra de progresso). O pywin32 é um *wrapper* abrangente para APIs Win32 COM e de sistema; seu **pró** é dar acesso de baixo nível a praticamente qualquer operação do Windows. Pode-se, por exemplo, usar `win32api.MoveFileEx` para mover arquivos com recursos específicos do NTFS, ou chamar funções da Shell para manipular a Lixeira. **Contras:** o pywin32 tem uma curva de aprendizado (é basicamente usar chamadas C do Windows via Python) e não é multiplataforma – deve ser usado condicionalmente só no Windows. Para a maioria das necessidades de I/O intensivo, shutil e os já dão conta, possivelmente combinados com threads.

No que tange a **operações concorrentes**, Python pode alavancar *multithreading* para I/O, pois operações de arquivo liberam o GIL durante espera de disco. Podemos usar `concurrent.futures.ThreadPoolExecutor` para efetuar múltiplas cópias simultaneamente, por exemplo. Isso pode acelerar a transferência de muitos arquivos pequenos ao sobrepor latências de acesso, embora para um único arquivo grande não haja ganho (o gargalo é o dispositivo). Estudos mostraram que para copiar dezenas de milhares de arquivos, uma implementação multi-thread pode ser ~10–15% mais rápida que processar sequencialmente ([Significantly improve `shutil.copytree`? - Ideas - Discussions on Python.org](https://discuss.python.org/t/significantly-improve-shutil-copytree/62078#:~:text=copy1%20costs%20173,81321870000102s)) ([Significantly improve `shutil.copytree`? - Ideas - Discussions on Python.org](https://discuss.python.org/t/significantly-improve-shutil-copytree/62078#:~:text=Use%20multithread%20can%20speed%20up,the%20multithread%20in%20the%20code)), ao custo de usar mais memória para buffers paralelos. Ou seja, **multithreading tende a ajudar em cenários de muitos arquivos**, enquanto **para poucos arquivos grandes a cópia sequencial já satura o disco**. Outra técnica é usar I/O assíncrona (asyncio) com `aiofiles`, mas internamente ela também delega a threads do sistema para operações de arquivo, então o benefício em Python puro é similar.

Para exclusão segura (mandar itens para a **Lixeira do Windows** em vez de apagar permanentemente), a biblioteca **Send2Trash** é uma solução de alto nível e multiplataforma. Com uma simples chamada `send2trash(path)`, o arquivo/pasta é movido para a lixeira nativa do OS. No Windows, o Send2Trash utiliza as chamadas da **Shell API (IFileOperation ou SHFileOperation)** para realizar isso ([Send2Trash · PyPI](https://pypi.org/project/Send2Trash/#:~:text=Send2Trash%20is%20a%20small%20package,org)), garantindo que o item apareça na Lixeira e possa ser restaurado manualmente pelo usuário. Sua implementação usa ctypes ou pywin32 nos bastidores, mas para o desenvolvedor a interface é trivial. O Send2Trash é amplamente utilizado por ser confiável e evitar perda de dados acidental (o usuário pode depois reverter deletados). Como **contra**, ele não oferece diretamente uma função de “restaurar” – isso fica a cargo do usuário (via Explorer) ou de uma biblioteca complementar.

Para implementar a funcionalidade de **restauração programática** da Lixeira, a biblioteca **winshell** é extremamente útil. Winshell é um *wrapper* leve para várias funções da shell do Windows (especial folders, atalhos, etc.), incluindo acesso detalhado à Lixeira. Através de `winshell.recycle_bin()` obtém-se um objeto iterável dos itens na lixeira, com atributos como caminho original e data de deleção ([Recycle Bin — winshell 0.6.4a documentation](https://winshell.readthedocs.io/en/latest/recycle-bin.html#:~:text=An%20object%20which%20represents%20the,folders%20within%20their%20specific%20drives)). E crucialmente, `winshell.undelete(path)` permite **restaurar o item mais recente com determinado caminho original** de volta ao local de origem ([Recycle Bin — winshell 0.6.4a documentation](https://winshell.readthedocs.io/en/latest/recycle-bin.html#:~:text=)). Ou seja, podemos usar winshell para percorrer itens na Lixeira e recuperar aqueles que correspondem aos arquivos que o programa moveu (implementando um recurso “Restaurar arquivos removidos”). O winshell por baixo utiliza COM (através de pywin32) para acionar a mesma lógica do Explorer de restaurar – garantindo que se um nome conflitar, o Windows renomeia como “Copy of …” automaticamente ([Recycle Bin — winshell 0.6.4a documentation](https://winshell.readthedocs.io/en/latest/recycle-bin.html#:~:text=Find%20the%20most%20recent%20version,The%20resulting%20filepath%20is%20returned)). Isso adiciona segurança e conveniência. O **pró** do winshell é simplificar tarefas complexas do Windows Shell; o **contra** é ser específico do Windows e um projeto não tão ativo (mas funcional nas versões atuais). Ainda assim, para nosso caso de uso, ter **Send2Trash para enviar à Lixeira** e **winshell para restaurar** forma uma combinação robusta. 

Operações de cópia e movimentação intensivas podem também se beneficiar de bibliotecas como **PyFilesystem2** (fs) que abstrai sistemas de arquivos e provê métodos de cópia recursiva, possivelmente com suporte a threads. Entretanto, adicionar essa camada pode ser desnecessário se focamos apenas em filesystem local. Em cenários extremos (milhões de arquivos), ferramentas externas como **robocopy** poderiam ser invocadas via subprocess para ganho de velocidade e resiliência, mas em geral o controle e portabilidade de fazer em Python (com shutil + threads) é preferível.

**Recomendação Final:** Para operações de arquivo intensivas e integração com o sistema, recomenda-se utilizar primariamente as **bibliotecas padrão (os, shutil)** pela confiabilidade e performance suficiente, complementando com ferramentas especializadas para Lixeira. Em prática: use `shutil.copy2`/`copytree` para copiar arquivos e diretórios – o shutil já aproveita chamadas otimizadas do SO quando possível ([shutil — High-level file operations — Python 3.13.3 documentation](https://docs.python.org/3/library/shutil.html#:~:text=copy,%E2%80%9D)) ([shutil — High-level file operations — Python 3.13.3 documentation](https://docs.python.org/3/library/shutil.html#:~:text=On%20Linux%20os)) – possivelmente distribuindo tarefas em threads se for preciso lidar com muitos arquivos em paralelo. Para exclusão de arquivos duplicados encontrados, em vez de remover diretamente, use **Send2Trash** para mandá-los à Lixeira de forma segura. Isso evita perdas irreversíveis e é uma abordagem user-friendly. Se o aplicativo precisa oferecer opção de “desfazer remoção”, integrar **winshell** para restaurar da Lixeira é altamente recomendado, pois facilita implementar um botão “Restaurar” que chama `winshell.undelete()` no item removido ([Recycle Bin — winshell 0.6.4a documentation](https://winshell.readthedocs.io/en/latest/recycle-bin.html#:~:text=)). Quanto a desempenho, shutil em conjunto com possível multithreading deve ser suficiente – se necessário, pode-se recorrer a chamadas do **PyWin32** para ações específicas (por ex., usar `win32file.DeleteFile` para bypass de restrições, ou `SHFileOperation` com múltiplos arquivos). No geral, essa combinação cobre robustez (via Lixeira), eficiência (cópia otimizada, threads) e segurança (possibilidade de restaurar), atendendo bem o módulo de manipulação de arquivos do aplicativo.

**Referências (Arquivos/Sistema):** 

- Documentação Python `shutil` – mudanças na cópia de arquivos (buffer maior no Windows, uso de chamadas de kernel no Unix) ([shutil — High-level file operations — Python 3.13.3 documentation](https://docs.python.org/3/library/shutil.html#:~:text=On%20Linux%20os)).  
- Discussão Python.org (2022) – *“Significantly improve shutil.copytree”* – indica ganho de desempenho ~10% com cópia multi-thread e consideraçõs de memória ([Significantly improve `shutil.copytree`? - Ideas - Discussions on Python.org](https://discuss.python.org/t/significantly-improve-shutil-copytree/62078#:~:text=copy1%20costs%20173,81321870000102s)) ([Significantly improve `shutil.copytree`? - Ideas - Discussions on Python.org](https://discuss.python.org/t/significantly-improve-shutil-copytree/62078#:~:text=Use%20multithread%20can%20speed%20up,the%20multithread%20in%20the%20code)).  
- PyPI Send2Trash – documentação menciona uso de IFileOperation/SHFileOperation nativo no Windows (via pywin32/ctypes) ([Send2Trash · PyPI](https://pypi.org/project/Send2Trash/#:~:text=Send2Trash%20is%20a%20small%20package,org)).  
- Winshell Docs – exemplo de uso de `winshell.undelete` para restaurar arquivos da Lixeira ([Recycle Bin — winshell 0.6.4a documentation](https://winshell.readthedocs.io/en/latest/recycle-bin.html#:~:text=)).  
- Stack Overflow – *“Restoring files from the recycle bin in python”* – discute abordagem com winshell para desfazer deleção ([Restoring files from the recycle bin in python - Stack Overflow](https://stackoverflow.com/questions/66650626/restoring-files-from-the-recycle-bin-in-python#:~:text=import%20winshell)) ([Recycle Bin — winshell 0.6.4a documentation](https://winshell.readthedocs.io/en/latest/recycle-bin.html#:~:text=Find%20the%20most%20recent%20version,The%20resulting%20filepath%20is%20returned)).  

## 4. Descompactação Otimizada de Arquivos (ZIP, RAR, 7z, etc.)

**Top 5 Candidatos (Bibliotecas de Descompressão):**

- **zipfile / tarfile (Stdlib)** – [Documentação zipfile](https://docs.python.org/3/library/zipfile.html)  
- **python-libarchive** (libarchive-c) – [PyPI python-libarchive](https://pypi.org/project/python-libarchive/)  
- **py7zr** – [PyPI py7zr](https://pypi.org/project/py7zr/)  
- **rarfile** – [PyPI rarfile](https://pypi.org/project/rarfile/)  
- **extractcode** – [PyPI extractcode](https://pypi.org/project/extractcode/)  

**Resumo Comparativo:**  
Para lidar com arquivos compactados contendo possíveis duplicatas (por exemplo, fotos zipadas ou coleções em .rar/.7z), é necessário capacidade de **listar e extrair** esses formatos de forma eficiente, de preferência sem precisar extrair tudo para analisar cada item. 

O Python inclui suporte embutido a alguns formatos: o módulo **zipfile** permite ler e extrair arquivos ZIP, e **tarfile** lida com tar (incluindo tar.gz, tar.bz2, etc.). Essas soluções padrão têm a vantagem de serem puras em Python (portáveis) e fáceis de usar. O `zipfile` em particular permite abrir um arquivo zip e **percorrer seu índice central rapidamente**, obtendo nomes, tamanhos e permitindo extrair seletivamente arquivos específicos via `ZipFile.open()` (que retorna um objeto tipo arquivo stream) ou `ZipFile.extract()` ([python-libarchive · PyPI](https://pypi.org/project/python-libarchive/#:~:text=The%20high%20level%20API%20provides,so%20do%20the%20compatibility%20wrappers)) ([python-libarchive · PyPI](https://pypi.org/project/python-libarchive/#:~:text=These%20compatibility%20wrappers%20are%20provided,module%20with%20the%20libarchive%20alternative)). Isso significa que a descompactação pode ser feita sob demanda – por exemplo, podemos iterar sobre cada item no zip, calcular o hash do seu conteúdo via um file-like, sem precisar extrair tudo em disco. Em termos de desempenho, embora muito do código do zipfile seja em Python, ele utiliza **zlib (C)** para descompressão dos dados, o que o torna razoavelmente eficiente. De fato, há relatos de que o zipfile puro-python chega a ter performance comparável ou melhor que utilitários externos ‘unzip’ em certos cenários ([zip - Why is the python zipfile module faster than C? - Stack Overflow](https://stackoverflow.com/questions/32575992/why-is-the-python-zipfile-module-faster-than-c#:~:text=In%20all%20cases%2C%20the%20performance,two%20extractors%20implemented%20in%20c)). O **ponto forte** do zipfile é a integração e simplicidade; um **ponto fraco** é a falta de suporte a formatos além de ZIP e TAR na biblioteca padrão – para RAR/7z é preciso bibliotecas extras. Além disso, zipfile não implementa multi-thread ou otimizações avançadas – extrair muitos arquivos pequenos pode ter overhead de Python significativo (percorrer 100k entradas pode ser mais lento que uma lib nativa). Ainda assim, para volumes moderados, o desempenho do zipfile é considerado satisfatório e **uso de streaming** evita picos de memória.

Para cobrir múltiplos formatos de forma otimizada, a biblioteca **libarchive** (via binding python-libarchive-c) é uma excelente opção. O libarchive é uma biblioteca C consolidada que suporta leitura de **diversos formatos (zip, tar, 7z, rar, cab, iso, etc.) e diversos algoritmos de compressão (gzip, bzip2, xz, lzma, zstd)** – tudo através de uma API de streaming unificada ([python-libarchive · PyPI](https://pypi.org/project/python-libarchive/#:~:text=Libarchive%20supports%20the%20following%3A)). Com python-libarchive, podemos abrir um arquivo de qualquer formato suportado e iterar item a item. Internamente, por ser implementado em C altamente otimizado, o libarchive tende a ter **desempenho nativo e uso de memória eficiente** ([python-libarchive · PyPI](https://pypi.org/project/python-libarchive/#:~:text=These%20compatibility%20wrappers%20are%20provided,module%20with%20the%20libarchive%20alternative)), tornando-o ideal para processar grandes arquivos compactados. Uma vantagem adicional é que o binding fornece wrappers para emular a interface do zipfile/tarfile do Python, facilitando substituição transparente em código existente – mas o uso direto de seu iterador de alto nível é recomendado para suportar todos formatos com a mesma lógica ([python-libarchive · PyPI](https://pypi.org/project/python-libarchive/#:~:text=These%20compatibility%20wrappers%20are%20provided,module%20with%20the%20libarchive%20alternative)). Em contrapartida, usar libarchive requer ter a biblioteca C instalada (no Windows isso pode ser não trivial – porém existem wheels precompilados para libarchive-c, facilitando). Além disso, por ser abrangente, pode incluir dependências pesadas (p. ex., suporte a rar via libunrar, que pode ou não estar presente, dependendo da build). No geral, o **pró** do libarchive é ser uma solução unificada e eficiente para **quase todos os formatos**, e o **contra** é adicionar uma dependência nativa. Em um ambiente que já precisa lidar com rar/7z, essa dependência se justifica.

Focando nos formatos específicos: **RAR** e **7-Zip (7z)** são muito comuns e não suportados nativamente pelo Python. 
- Para **RAR**, a biblioteca mais usada é **rarfile**. Ela imita a interface do zipfile (você pode chamar `RarFile.namelist(), .extractall()` etc.). O rarfile tem a capacidade de ler a estrutura do .rar em Python puro (suporta RAR3 e RAR5) ([rarfile · PyPI](https://pypi.org/project/rarfile/#:~:text=,RAR5%20format%20archives)), mas para extrair o conteúdo de arquivos comprimidos ele depende de utilitários externos: **requer que o executável `unrar` (oficial da RARLAB) ou `unar` ou `7z` esteja instalado**, pois invoca esses para cada arquivo compactado que vai extrair ([rarfile · PyPI](https://pypi.org/project/rarfile/#:~:text=%2A%20Archive%20parsing%20and%20non,handled%20in%20pure%20Python%20code)). Isso significa que listar conteúdo é possível sem nada extra, mas ao realmente extrair dados, o desempenho e sucesso dependem desses programas externos. O **pró** do rarfile é simplicidade de uso e integração com Python (e suporte a recursos como volumes e senhas), mas os **contras** são: (1) **necessidade de instalar software externo** (unrar não é livre, embora seja gratuito para uso – o rarfile vai tentar usar se disponível), (2) possível overhead ao chamar um subprocess para cada arquivo ou operação, e (3) impossibilidade de streaming real via Python (já que delega a outro processo a descompressão). Outra alternativa é o **python-unrar** (unrar.dll via ctypes), que usa a biblioteca UnRAR da RARLAB dentro do processo Python – evitando overhead de processos e permitindo streaming – porém sua licença é restritiva (só para uso não comercial, por ser derivado do código RAR) e exige passos adicionais para instalar a DLL no sistema ([unrar · PyPI](https://pypi.org/project/unrar/#:~:text=python,download%20UnRAR%20library%20sources%20from)) ([unrar · PyPI](https://pypi.org/project/unrar/#:~:text=For%20Windows%20you%20can%20also,exe)). Em resumo, para RAR: rarfile é conveniente mas pode ser menos performático, python-unrar é rápida mas de uso limitado/licença não OSS.

- Para **7z**, existe a biblioteca **py7zr**, escrita em Python puro, que consegue ler e escrever arquivos .7z. Ela suporta compressão LZMA/LZMA2, e até recursos como encriptação e múltiplos métodos (BZip2, Deflate, Zstandard via libs adicionais) ([py7zr · PyPI](https://pypi.org/project/py7zr/#:~:text=py7zr%20supports%20algorithms%20and%20filters,PPMd%20with%20third%20party%20libraries)). O py7zr facilita extrair ou listar conteúdo sem precisar do 7-Zip instalado. Entretanto, por ser implementada em Python, **py7zr é mais lenta** que a ferramenta nativa 7z.exe. Os próprios autores notam que o py7zr funciona bem, mas fica **várias vezes mais lento que a implementação C++ do 7-Zip** e consome centenas de MB de RAM ao extrair itens grandes ([py7zr · PyPI](https://pypi.org/project/py7zr/#:~:text=You%20can%20find%20a%20compression,wiki%20page%5D%28https%3A%2F%2Fgithub.com%2Fmiurahr%2Fpy7zr%2Fwiki%2FBenchmarks)). Em benchmarks, extrair via py7zr pode demorar significativamente mais – portanto, se desempenho for crítico (por exemplo, extrair um .7z gigante com milhares de arquivos), talvez seja melhor chamar diretamente o executável 7z (p7zip) via subprocess. Ainda assim, py7zr tem a vantagem de **suporte total em Python, inclusive de arquivos 7z criptografados**, o que torna a integração mais simples. O **pró** é o suporte dedicado a 7z no próprio Python; o **contra** é performance e uso de memória, especialmente comparado ao libarchive ou 7-Zip nativo ([py7zr · PyPI](https://pypi.org/project/py7zr/#:~:text=py7zr%20works%20well%2C%20but%20slower,run%20python%20interface)) ([py7zr · PyPI](https://pypi.org/project/py7zr/#:~:text=recommended%20to%20use%20these%20alternatives,run%20python%20interface)). Vale mencionar que 7z é um formato “sólido” por padrão – arquivos são comprimidos em bloco contínuo – então extrair apenas um arquivo do meio pode requerer descompactar uma sequência inteira, o que pode ser lento independentemente da biblioteca.

Para casos em que se quer **confiabilidade e abrangência máxima**, existe a ferramenta **extractcode**. Ela não é exatamente uma biblioteca de baixo nível, mas um utilitário Python que combina **7-zip, libarchive e métodos nativos** para extrair *qualquer* formato de maneira robusta ([extractcode · PyPI](https://pypi.org/project/extractcode/#:~:text=Released%3A%20%20May%209%2C%202022)) ([extractcode · PyPI](https://pypi.org/project/extractcode/#:~:text=A%20mostly%20universal%20archive%20extractor,library%20for%20reliable%20archive%20extraction)). É mantida pelo projeto Scancode e suporta dezenas de formatos, tentando primeiro 7z, depois libarchive, etc., para garantir extração completa. O extractcode é ideal quando você precisa lidar com arquivos potencialmente corrompidos ou formatos obscuros, priorizando *coverage* sobre performance. Ele inclui inclusive suporte a ISO, instaladores (NSIS, MSI) e outros via os backend citados. Em contrapartida, é uma dependência pesada (pode incluir binaries ou exigir instalação do 7z externo) e foca em extrair tudo para disco (não provê API de streaming). No contexto de deduplicação, talvez seja um exagero, mas é uma opção a considerar se quisermos um “extrair qualquer coisa” out-of-the-box. 

**Recomendação Final:** Considerando desempenho e flexibilidade, a recomendação principal para descompactação otimizada é utilizar o **python-libarchive (libarchive)** sempre que possível. Ele permitirá que o aplicativo **abra arquivos ZIP/RAR/7Z de forma unificada e leia seus conteúdos sob demanda** em streaming, aproveitando a eficiência do código nativo C ([python-libarchive · PyPI](https://pypi.org/project/python-libarchive/#:~:text=These%20compatibility%20wrappers%20are%20provided,module%20with%20the%20libarchive%20alternative)) ([python-libarchive · PyPI](https://pypi.org/project/python-libarchive/#:~:text=of%20the%20standard%20modules%20is,module%20with%20the%20libarchive%20alternative)). Com libarchive, pode-se iterar pelos arquivos internos e calcular hashes sem escrever no disco, ou extrair seletivamente apenas os necessários. Isso se alinha ao objetivo de detectar duplicatas: por exemplo, podemos calcular o hash de cada foto dentro de um zip diretamente, evitando extrair tudo. Em cenários onde não seja viável usar libarchive (por dificuldade de instalação no Windows ou restrições), usar uma combinação das libs específicas é o próximo passo: **zipfile** para ZIP (é eficiente e já comprovado ([zip - Why is the python zipfile module faster than C? - Stack Overflow](https://stackoverflow.com/questions/32575992/why-is-the-python-zipfile-module-faster-than-c#:~:text=In%20all%20cases%2C%20the%20performance,two%20extractors%20implemented%20in%20c))), **rarfile** para RAR (lembrando de distribuir o unrar.exe junto ao app ou instruir o usuário a instalá-lo), e **py7zr** para 7Z se performance não for crítica. Nesses casos, pode-se mitigar o desempenho executando as extrações pesadas em um thread separado ou processo (para não travar a GUI), ou no limite usando subprocess com a ferramenta nativa (7z) para arquivos .7z muito grandes – talvez com uma barra de progresso. Se a prioridade for **não depender de ferramentas externas** e manter tudo em Python, então zipfile+py7zr+rarfile cobrem os formatos principais com um mínimo de fricção. Contudo, o **libarchive** ganha como solução mais **otimizada e completa**, inclusive futuro-proof (já lidando com formatos como tar.xz, etc., que podem aparecer). Em suma, para extrair e analisar arquivos compactados em alta velocidade no aplicativo de deduplicação, **adotar o libarchive via python-libarchive-c é a opção de melhor desempenho e versatilidade**, com fallback para as bibliotecas puras Python onde necessário.

**Referências (Descompactação):** 

- Python Wiki – *“GuiProgramming”* – menciona binding para CEF e lista toolkits (PyQt, wxPython, PyGTK, Kivy), confirmando ecossistema GUI Python. ([GuiProgramming - Python Wiki](https://wiki.python.org/moin/GuiProgramming#:~:text=GuiProgramming%20,PyGObject%2C%20Kivy%20and%20PyGame%2FPyOpenGL))  
- PyPI python-libarchive (2022) – documentação enfatiza suporte a múltiplos formatos e **desempenho nativo/memória otimizada** comparado aos módulos padrão ([python-libarchive · PyPI](https://pypi.org/project/python-libarchive/#:~:text=These%20compatibility%20wrappers%20are%20provided,module%20with%20the%20libarchive%20alternative)).  
- Stack Overflow – *“Why is Python zipfile faster than C?”* (2014) – autor observa que zipfile (Python) teve performance similar ou superior a utilitários C testados em um conjunto de arquivos ([zip - Why is the python zipfile module faster than C? - Stack Overflow](https://stackoverflow.com/questions/32575992/why-is-the-python-zipfile-module-faster-than-c#:~:text=In%20all%20cases%2C%20the%20performance,two%20extractors%20implemented%20in%20c)).  
- PyPI rarfile (2024) – descrição dos recursos e nota de que arquivos comprimidos são extraídos via ferramenta externa (unrar/7z) ([rarfile · PyPI](https://pypi.org/project/rarfile/#:~:text=,comments)).  
- PyPI py7zr (2024) – nota de benchmarks: *“py7zr funciona bem, porém mais lento que implementações C++ (7-zip) – se performance for crucial, usar subprocess com 7z”* ([py7zr · PyPI](https://pypi.org/project/py7zr/#:~:text=You%20can%20find%20a%20compression,wiki%20page%5D%28https%3A%2F%2Fgithub.com%2Fmiurahr%2Fpy7zr%2Fwiki%2FBenchmarks)) ([py7zr · PyPI](https://pypi.org/project/py7zr/#:~:text=py7zr%20works%20well%2C%20but%20slower,run%20python%20interface)).  
- Documentação winshell – classe ShellRecycleBin e método undelete para restaurar arquivos ([Recycle Bin — winshell 0.6.4a documentation](https://winshell.readthedocs.io/en/latest/recycle-bin.html#:~:text=)) ([Recycle Bin — winshell 0.6.4a documentation](https://winshell.readthedocs.io/en/latest/recycle-bin.html#:~:text=The%20object%20,of%20a%20given%20original%20filepath)). (Included in previous section references)